{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('/home/safiyyah/Documents/Courses/project3004/Oto-InnerEar/organized.csv')\n",
    "#df=pd.read_csv('organized.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database contains TEOAE signals collected from 54 individuals or subjects.\n",
    "For each subject there are 2 recording sessions - 0 and 1 - separated by 1 week, atleast.\n",
    "In each session, recording is done for both right and left ears.\n",
    "For each ear, recording is done using 2 microphones (called as 2 buffers A and B)\n",
    "The raw dataset has a total of 50986 TEOAE signals recorded from 54 subjects - (data matrix size:50986 x 665)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each row: columns with labels --> data_0 to data_659 contain one TEOAE response.  The no. of TEOAE responses for each condition (e.g., subject 0, session 0, ear = left, buffer =B) varies from 27 to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly\n",
    "#import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 10 TEOAE signals are observed to be very similar (steady) for a person,\n",
    "yet these signals are very different for different individuals --> i.e., intraclass variability is low, while interclass variability is high.\n",
    "\n",
    "This could mean that different subject's TEOAE signals contain different frequency components.\n",
    "\n",
    "So, we extract frequency information from the signals using Fast Fourier Transform (fft), power spectral density (psd) and autocorrelation --> these frequency related information is used as feature input to the machine learning algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "#df.groupby(['subject', 'session', 'ear', 'buffer'],as_index=False)['data_0',''].agg(lambda x:list(x))\n",
    "\n",
    "#dfu0=df.groupby(['subject', 'session', 'ear', 'buffer']).get_group((0,0,'right','A')).iloc[-10:]\n",
    "\n",
    "def subject0(subjectno, sessionno, earname, bufferid):\n",
    "    dfu0=df.groupby(['subject', 'session', 'ear', 'buffer']).get_group((subjectno, sessionno, earname, bufferid)).iloc[-10:]\n",
    "    return dfu0\n",
    "\n",
    "x=subject0(34,1,'left','B')\n",
    "x['subject'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extracts 80 responses for each of the 54 subjects: \n",
    "# for each subject: a total of 80 last 10 responses corresponding to the 8 different recording conditions\n",
    "#the 8 conditions are:\n",
    "# for subject = i --> session = 0/1 , ear = left/right, buffer = A/B ( 2 sessions * 2 ears * 2 buffers)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "allInputTEOAEsignalsAllSubjects = pd.DataFrame([])\n",
    "allOutputLabelsAllSubjects = pd.DataFrame([])\n",
    "\n",
    "#temp=pd.DataFrame([])\n",
    "for a in range(54):\n",
    "    if a==48:\n",
    "        print('passing on')\n",
    "        continue\n",
    "    #for each subject a \n",
    "    print(a)\n",
    "    df1 = pd.DataFrame([])\n",
    "    #a=list(range(0,1))\n",
    "    b=[0,1]              # sessions 0 and 1\n",
    "    c=['left','right']   # ears \n",
    "    d=['A','B']          # buffers\n",
    "    \n",
    "    allFeatures =  pd.DataFrame([])\n",
    "    allInputFeatures =  pd.DataFrame([])\n",
    "    outputLabel =  pd.DataFrame([])\n",
    "    fftValues =  pd.DataFrame([])\n",
    "    psdValues =  pd.DataFrame([])\n",
    "    autocorrValues = pd.DataFrame([])\n",
    "        \n",
    "    for q,r,s in [(q,r,s) for q in b for r in c for s in d]:\n",
    "        \n",
    "        # df1 contains all the 80 TEOAE signals of subject a\n",
    "        df1 = df1.append(subject0(a,q,r,s))\n",
    "        allInputFeatures = df1.iloc[:,5:]\n",
    "    \n",
    "    allInputTEOAEsignalsAllSubjects = pd.concat([allInputTEOAEsignalsAllSubjects.reset_index(drop=True),\n",
    "                                                 allInputFeatures.reset_index(drop=True)], axis=0)\n",
    "    # the following gets you the class label <= subject no.[0,1,2,...,53]\n",
    "    outputLabel = df1.iloc[:,0] \n",
    "    #allOutputLabelsAllSubjects = allOutputLabelsAllSubjects.append(outputLabel)\n",
    "    #append didn't work for output so using pd.cat instead\n",
    "    allOutputLabelsAllSubjects = pd.concat([allOutputLabelsAllSubjects.reset_index(drop=True),\n",
    "                                            outputLabel.reset_index(drop=True)], axis=0)\n",
    "    #print(allOutputLabelsAllSubjects.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allInputTEOAEsignalsAllSubjects.shape)\n",
    "print(allOutputLabelsAllSubjects.shape)\n",
    "X = allInputTEOAEsignalsAllSubjects\n",
    "y = allOutputLabelsAllSubjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.iloc[:3760]\n",
    "y=y.iloc[:3760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save extracted dataframe locally\n",
    "xsave = X\n",
    "ysave = y\n",
    "xsave.to_pickle('dataX.pkl')\n",
    "ysave.to_pickle('labelY.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = allInputTEOAEsignalsAllSubjects.iloc[1101:1111,:]\n",
    "#y = allOutputLabelsAllSubjects.iloc[1101:1111]\n",
    "#print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from pkl files\n",
    "X = pd.read_pickle('dataX.pkl')\n",
    "y = pd.read_pickle('labelY.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=allInputFeatsAllSubjects.iloc[:,130:256]\n",
    "#y=allOutputLabelsAllSubjects\n",
    "#y=y.astype(int)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train)\n",
    "print(y_test.shape)\n",
    "3456 % len(X_train) ==0\n",
    "'''\n",
    "print(np.asarray(X_train).shape)\n",
    "print(np.asarray(X_test).shape)\n",
    "print(np.asarray(y_train).shape)\n",
    "print(np.asarray(y_test).shape)\n",
    "\n",
    "labels_train = list(map(lambda x: int(x), np.asarray(y_train)))\n",
    "print(np.asarray(labels_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "scales = range(1,661)\n",
    "waveletname = 'morl'\n",
    "train_size = 5000\n",
    "test_size= 500\n",
    "\n",
    "#################################################\n",
    "### plotting CWT of a single TEOAE signal  ######\n",
    "#################################################\n",
    "coeff, freq = pywt.cwt(X_train.iloc[1,:], scales, waveletname, 1)\n",
    "plt.matshow(coeff,  cmap='PRGn', aspect='auto')\n",
    "plt.show()\n",
    "    \n",
    "'''\n",
    "    N = X_train.shape[0]\n",
    "t0=1871\n",
    "dt=0.25\n",
    "time = np.arange(0, N) * dt + t0\n",
    "\n",
    "def plot_wavelet(time, signal, scales, \n",
    "                 waveletname = 'cmor', \n",
    "                 cmap = plt.cm.seismic, \n",
    "                 title = 'Wavelet Transform (Power Spectrum) of signal', \n",
    "                 ylabel = 'Period (years)', \n",
    "                 xlabel = 'Time'):    \n",
    "    dt = time[1] - time[0]\n",
    "    [coefficients, frequencies] = pywt.cwt(signal, scales, waveletname, dt)\n",
    "    power = (abs(coefficients)) ** 2\n",
    "    period = 1. / frequencies\n",
    "    levels = [0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8]\n",
    "    contourlevels = np.log2(levels)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    im = ax.contourf(time, np.log2(period), np.log2(power), contourlevels, extend='both',cmap=cmap)\n",
    "    \n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=18)\n",
    "    ax.set_xlabel(xlabel, fontsize=18)\n",
    "    \n",
    "    yticks = 2**np.arange(np.ceil(np.log2(period.min())), np.ceil(np.log2(period.max())))\n",
    "    ax.set_yticks(np.log2(yticks))\n",
    "    ax.set_yticklabels(yticks)\n",
    "    ax.invert_yaxis()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_ylim(ylim[0], -1)\n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.95, 0.5, 0.03, 0.25])\n",
    "    fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\")\n",
    "    plt.show()\n",
    "\n",
    "plot_wavelet(time, X_train.iloc[1,:], scales)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "scales = range(1,X_train.shape[1]+1)\n",
    "waveletname = 'morl'\n",
    "train_size = X_train.shape[0]\n",
    "test_size= X_test.shape[0]\n",
    "\n",
    "#########################################################\n",
    "### creating a tensor to store CWT matrices of train egs#\n",
    "#########################################################\n",
    "train_data_cwt = np.ndarray(shape=(train_size, 660, 660))\n",
    "#train_data_cwt = np.ndarray(shape=(660, 660, train_size))\n",
    "### a TEOAE signal has 660 samples; \n",
    "### so, its CWT is of size 660 X 660\n",
    "### train_data_cwt is a tensor with train_size no. of 660X660 matrices\n",
    "\n",
    "for ii in range(0,train_size):\n",
    "    if ii % 50 == 0: #len(X_train) == 0:\n",
    "        print(ii)\n",
    "    signal = X_train.iloc[ii, :]\n",
    "    coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n",
    "    coeff_ = coeff[:,:660]\n",
    "    train_data_cwt[ii, :, :] = coeff_\n",
    "    #train_data_cwt[:, :, ii] = coeff_\n",
    "\n",
    "###########################################################\n",
    "### creating a tensor to store CWT matrices of test egs ###\n",
    "###########################################################\n",
    "test_data_cwt = np.ndarray(shape=(test_size, 660, 660))\n",
    "#test_data_cwt = np.ndarray(shape=(660, 660, test_size))\n",
    "### test_data_cwt is a tensor with test_size no. of 660X660 matrices\n",
    "\n",
    "for ii in range(0,test_size):\n",
    "    if ii % len(X_test) == 0:\n",
    "        print(ii)\n",
    "    signal = X_test.iloc[ii, :]\n",
    "    coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n",
    "    coeff_ = coeff[:,:660]\n",
    "    test_data_cwt[ii, :, :] = coeff_\n",
    "    #test_data_cwt[:, :, ii] = coeff_\n",
    "\n",
    "###########################################################\n",
    "### convert the labels from float to int of train and test egs\n",
    "###########################################################\n",
    "labels_train = list(map(lambda x: int(x), np.asarray(y_train)))\n",
    "labels_test = list(map(lambda x: int(x), np.asarray(y_test)))\n",
    "\n",
    "###########################################################\n",
    "### putting all the train and test CWT data             ###\n",
    "###########################################################\n",
    "x_train = train_data_cwt\n",
    "y_train = list(labels_train[:train_size])\n",
    "x_test = test_data_cwt\n",
    "y_test = list(labels_test[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array\n",
    "np.save('x_train_CNN', x_train)\n",
    "np.save('x_test_CNN', x_test)\n",
    "y_train_np = np.asarray(y_train)\n",
    "np.save('y_train_CNN', y_train_np)\n",
    "y_test_np = np.asarray(y_test)\n",
    "np.save('y_test_CNN', y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(x_train).shape)\n",
    "print(np.asarray(x_test).shape)\n",
    "print(np.asarray(y_train).shape)\n",
    "print(np.asarray(y_test).shape)\n",
    "print(len(x_train))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "x_train = np.load('x_train_CNN.npy')\n",
    "x_test = np.load('x_test_CNN.npy')\n",
    "y_train_np = np.load('y_train_CNN.npy')\n",
    "y_test_np = np.load('y_test_CNN.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008, 660, 660, 1)\n",
      "(3008, 660, 660, 1)\n",
      "Train on 3008 samples, validate on 752 samples\n",
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 17s 6ms/step - loss: 3.9688 - acc: 0.0209 - val_loss: 3.9618 - val_acc: 0.0186\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.9354 - acc: 0.0219 - val_loss: 3.9325 - val_acc: 0.0186\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.9078 - acc: 0.0223 - val_loss: 3.9108 - val_acc: 0.0146\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.8824 - acc: 0.0216 - val_loss: 3.8948 - val_acc: 0.0279\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 17s 6ms/step - loss: 3.8246 - acc: 0.0372 - val_loss: 3.8094 - val_acc: 0.0253\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.7360 - acc: 0.0512 - val_loss: 3.6650 - val_acc: 0.0572\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.5129 - acc: 0.0924 - val_loss: 3.4232 - val_acc: 0.1024\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.3044 - acc: 0.1180 - val_loss: 3.2690 - val_acc: 0.1117\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.1392 - acc: 0.1456 - val_loss: 3.1530 - val_acc: 0.1370\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 3.0057 - acc: 0.1752 - val_loss: 3.0418 - val_acc: 0.1755\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 2.8993 - acc: 0.1951 - val_loss: 2.9869 - val_acc: 0.1862\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.7941 - acc: 0.2121 - val_loss: 2.8617 - val_acc: 0.1955\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.6945 - acc: 0.2360 - val_loss: 2.8189 - val_acc: 0.1995\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.6281 - acc: 0.2447 - val_loss: 2.8466 - val_acc: 0.2221\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.5388 - acc: 0.2663 - val_loss: 2.6942 - val_acc: 0.2314\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.4789 - acc: 0.2793 - val_loss: 2.6537 - val_acc: 0.2394\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.3955 - acc: 0.2926 - val_loss: 2.5261 - val_acc: 0.2819\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 2.3290 - acc: 0.3298 - val_loss: 2.5028 - val_acc: 0.2872\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 2.2520 - acc: 0.3424 - val_loss: 2.5000 - val_acc: 0.2846\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.1999 - acc: 0.3590 - val_loss: 2.3897 - val_acc: 0.3152\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.1295 - acc: 0.3637 - val_loss: 2.3205 - val_acc: 0.3431\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 2.0529 - acc: 0.3903 - val_loss: 2.2907 - val_acc: 0.3285\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.9882 - acc: 0.3959 - val_loss: 2.1792 - val_acc: 0.3750\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.9332 - acc: 0.4112 - val_loss: 2.2294 - val_acc: 0.3418\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.8545 - acc: 0.4448 - val_loss: 2.1536 - val_acc: 0.3444\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.8264 - acc: 0.4448 - val_loss: 1.9662 - val_acc: 0.4136\n",
      "Epoch 27/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.7298 - acc: 0.4651 - val_loss: 1.9534 - val_acc: 0.4176\n",
      "Epoch 28/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.6432 - acc: 0.5033 - val_loss: 1.8435 - val_acc: 0.4495\n",
      "Epoch 29/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.6187 - acc: 0.5090 - val_loss: 1.8046 - val_acc: 0.4707\n",
      "Epoch 30/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.5473 - acc: 0.5239 - val_loss: 1.6988 - val_acc: 0.4801\n",
      "Epoch 31/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.4501 - acc: 0.5628 - val_loss: 1.6299 - val_acc: 0.5106\n",
      "Epoch 32/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.4067 - acc: 0.5698 - val_loss: 1.5814 - val_acc: 0.5426\n",
      "Epoch 33/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.3671 - acc: 0.5818 - val_loss: 1.5674 - val_acc: 0.5426\n",
      "Epoch 34/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.3022 - acc: 0.6037 - val_loss: 1.5159 - val_acc: 0.5665\n",
      "Epoch 35/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.2401 - acc: 0.6230 - val_loss: 1.4674 - val_acc: 0.5479\n",
      "Epoch 36/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.1690 - acc: 0.6426 - val_loss: 1.3372 - val_acc: 0.6077\n",
      "Epoch 37/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.1226 - acc: 0.6549 - val_loss: 1.3752 - val_acc: 0.5745\n",
      "Epoch 38/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 1.1275 - acc: 0.6466 - val_loss: 1.2994 - val_acc: 0.6210\n",
      "Epoch 39/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 1.0208 - acc: 0.6875 - val_loss: 1.2411 - val_acc: 0.6210\n",
      "Epoch 40/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.9683 - acc: 0.7094 - val_loss: 1.2929 - val_acc: 0.6051\n",
      "Epoch 41/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.9603 - acc: 0.7025 - val_loss: 1.1577 - val_acc: 0.6343\n",
      "Epoch 42/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.8918 - acc: 0.7301 - val_loss: 1.0839 - val_acc: 0.6902\n",
      "Epoch 43/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.8059 - acc: 0.7533 - val_loss: 1.0918 - val_acc: 0.6689\n",
      "Epoch 44/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.8193 - acc: 0.7360 - val_loss: 1.0248 - val_acc: 0.7061\n",
      "Epoch 45/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.7250 - acc: 0.7859 - val_loss: 0.9888 - val_acc: 0.7088\n",
      "Epoch 46/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.6963 - acc: 0.7892 - val_loss: 1.1350 - val_acc: 0.6622\n",
      "Epoch 47/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.7742 - acc: 0.7563 - val_loss: 0.9833 - val_acc: 0.7035\n",
      "Epoch 48/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.7102 - acc: 0.7803 - val_loss: 0.9871 - val_acc: 0.7114\n",
      "Epoch 49/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.6053 - acc: 0.8285 - val_loss: 0.8100 - val_acc: 0.7819\n",
      "Epoch 50/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.5542 - acc: 0.8431 - val_loss: 0.8106 - val_acc: 0.7766\n",
      "Epoch 51/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 0.5156 - acc: 0.8554 - val_loss: 0.7929 - val_acc: 0.7939\n",
      "Epoch 52/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.5121 - acc: 0.8551 - val_loss: 0.7704 - val_acc: 0.8032\n",
      "Epoch 53/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4574 - acc: 0.8813 - val_loss: 0.7707 - val_acc: 0.7686\n",
      "Epoch 54/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4459 - acc: 0.8707 - val_loss: 0.7070 - val_acc: 0.8032\n",
      "Epoch 55/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4387 - acc: 0.8767 - val_loss: 0.7504 - val_acc: 0.7939\n",
      "Epoch 56/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4196 - acc: 0.8856 - val_loss: 0.6834 - val_acc: 0.8098\n",
      "Epoch 57/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4137 - acc: 0.8787 - val_loss: 0.6439 - val_acc: 0.8085\n",
      "Epoch 58/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.4166 - acc: 0.8773 - val_loss: 0.6670 - val_acc: 0.8125\n",
      "Epoch 59/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.3393 - acc: 0.9089 - val_loss: 0.5498 - val_acc: 0.8630\n",
      "Epoch 60/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.3130 - acc: 0.9235 - val_loss: 0.5684 - val_acc: 0.8564\n",
      "Epoch 61/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.3095 - acc: 0.9139 - val_loss: 0.5317 - val_acc: 0.8630\n",
      "Epoch 62/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2956 - acc: 0.9205 - val_loss: 0.5341 - val_acc: 0.8670\n",
      "Epoch 63/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.3033 - acc: 0.9166 - val_loss: 0.6193 - val_acc: 0.8351\n",
      "Epoch 64/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2916 - acc: 0.9192 - val_loss: 0.5416 - val_acc: 0.8644\n",
      "Epoch 65/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2576 - acc: 0.9295 - val_loss: 0.5393 - val_acc: 0.8630\n",
      "Epoch 66/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2398 - acc: 0.9375 - val_loss: 0.4462 - val_acc: 0.8923\n",
      "Epoch 67/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2130 - acc: 0.9495 - val_loss: 0.4673 - val_acc: 0.8816\n",
      "Epoch 68/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1916 - acc: 0.9578 - val_loss: 0.4330 - val_acc: 0.9082\n",
      "Epoch 69/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1864 - acc: 0.9551 - val_loss: 0.4330 - val_acc: 0.8763\n",
      "Epoch 70/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1727 - acc: 0.9638 - val_loss: 0.4128 - val_acc: 0.9043\n",
      "Epoch 71/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1899 - acc: 0.9541 - val_loss: 0.3858 - val_acc: 0.9056\n",
      "Epoch 72/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1640 - acc: 0.9618 - val_loss: 0.4369 - val_acc: 0.9003\n",
      "Epoch 73/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1638 - acc: 0.9638 - val_loss: 0.3473 - val_acc: 0.9215\n",
      "Epoch 74/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1492 - acc: 0.9661 - val_loss: 0.3389 - val_acc: 0.9082\n",
      "Epoch 75/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 0.1924 - acc: 0.9505 - val_loss: 0.5903 - val_acc: 0.8404\n",
      "Epoch 76/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.3089 - acc: 0.9106 - val_loss: 0.6206 - val_acc: 0.8191\n",
      "Epoch 77/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2550 - acc: 0.9186 - val_loss: 0.3716 - val_acc: 0.9016\n",
      "Epoch 78/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1349 - acc: 0.9678 - val_loss: 0.3500 - val_acc: 0.9109\n",
      "Epoch 79/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1096 - acc: 0.9747 - val_loss: 0.3086 - val_acc: 0.9176\n",
      "Epoch 80/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0913 - acc: 0.9884 - val_loss: 0.2605 - val_acc: 0.9428\n",
      "Epoch 81/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0809 - acc: 0.9890 - val_loss: 0.2700 - val_acc: 0.9455\n",
      "Epoch 82/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0872 - acc: 0.9854 - val_loss: 0.3624 - val_acc: 0.9069\n",
      "Epoch 83/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2741 - acc: 0.9166 - val_loss: 0.6321 - val_acc: 0.8285\n",
      "Epoch 84/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 0.1737 - acc: 0.9528 - val_loss: 0.3001 - val_acc: 0.9149\n",
      "Epoch 85/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1089 - acc: 0.9767 - val_loss: 0.2669 - val_acc: 0.9441\n",
      "Epoch 86/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0737 - acc: 0.9867 - val_loss: 0.2218 - val_acc: 0.9588\n",
      "Epoch 87/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0661 - acc: 0.9910 - val_loss: 0.2361 - val_acc: 0.9495\n",
      "Epoch 88/100\n",
      "3008/3008 [==============================] - 16s 5ms/step - loss: 0.0571 - acc: 0.9927 - val_loss: 0.2157 - val_acc: 0.9561\n",
      "Epoch 89/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0548 - acc: 0.9937 - val_loss: 0.2607 - val_acc: 0.9428\n",
      "Epoch 90/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0584 - acc: 0.9914 - val_loss: 0.2245 - val_acc: 0.9521\n",
      "Epoch 91/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0632 - acc: 0.9904 - val_loss: 0.2655 - val_acc: 0.9322\n",
      "Epoch 92/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.1027 - acc: 0.9811 - val_loss: 0.5096 - val_acc: 0.8723\n",
      "Epoch 93/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.2229 - acc: 0.9315 - val_loss: 0.3588 - val_acc: 0.9003\n",
      "Epoch 94/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0955 - acc: 0.9734 - val_loss: 0.2368 - val_acc: 0.9362\n",
      "Epoch 95/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0602 - acc: 0.9867 - val_loss: 0.2091 - val_acc: 0.9508\n",
      "Epoch 96/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0453 - acc: 0.9963 - val_loss: 0.1840 - val_acc: 0.9601\n",
      "Epoch 97/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0358 - acc: 0.9980 - val_loss: 0.1794 - val_acc: 0.9654\n",
      "Epoch 98/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0296 - acc: 0.9987 - val_loss: 0.1776 - val_acc: 0.9601\n",
      "Epoch 99/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0276 - acc: 0.9983 - val_loss: 0.1698 - val_acc: 0.9588\n",
      "Epoch 100/100\n",
      "3008/3008 [==============================] - 15s 5ms/step - loss: 0.0241 - acc: 0.9997 - val_loss: 0.1862 - val_acc: 0.9588\n",
      "Train loss: 0.02270747428423071, Train accuracy: 0.9993351063829787\n",
      "Test loss: 0.18622717237535943, Test accuracy: 0.9587765957446809\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    " \n",
    "img_x = x_train.shape[1] # = no.of samples of each TEOAE signal = 660\n",
    "img_y = x_train.shape[1] \n",
    "img_z = 1 #x_train.shape[2] # Z =8 = no. of train egs --> chumma trying\n",
    "\n",
    "input_shape = (img_x, img_y, img_z)\n",
    " \n",
    "num_classes = 54\n",
    "batch_size = 64\n",
    "#num_classes = 54\n",
    "epochs = 100\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "#x_train = np.expand_dims(x_train, axis=0)\n",
    "#x_test = np.expand_dims(x_test, axis=0)\n",
    "\n",
    "#x_train = x_train.reshape(3456,660,660,1)#len(x_train),img_x, img_y, img_z)\n",
    "#x_test = x_test.reshape(864,660,660,1)#len(x_test),img_x, img_y, img_z)\n",
    "\n",
    "\n",
    "#(3008, 660, 660)\n",
    "#(752, 660, 660)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(3008,660,660,1)#len(x_train),img_x, img_y, img_z)\n",
    "x_test = x_test.reshape(752,660,660,1)#len(x_test),img_x, img_y, img_z)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    " \n",
    "y_train = keras.utils.to_categorical(y_train_np, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_np, num_classes)\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy']) \n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])\n",
    " \n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1 ,2 ,3,1],[4, 5 ,1,6],[6, 7, 2,8],[12,13,1, 4],[15,16,1,7]]\n",
    "a=np.asarray(a)\n",
    "print(a.shape)\n",
    "b.reshape(2,2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(hidden_layer_sizes=(40,10,40),solver='sgd',alpha=.0001,tol=.01,activation='relu')\n",
    "#clf=MLPClassifier(hidden_layer_sizes=(1032,129,1032),solver='sgd',alpha=.0001,tol=.01,activation='tanh')\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "clf.score(X_test,y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "clf=svm.SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "clf.score(X_test,y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf=Perceptron(tol=.01,random_state=0,max_iter=50,alpha=.00001)\n",
    "clf.fit(X_train,y_train.values.ravel())\n",
    "clf.score(X_test,y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "###   %history -g -f recovered.txt\n",
    "########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
